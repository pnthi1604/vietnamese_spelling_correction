{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phamngocthi/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/phamngocthi/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from underthesea import word_tokenize\n",
    "from pyvi import ViTokenizer\n",
    "import os\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import re\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from torchmetrics import Recall, Precision, FBetaScore, Accuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "# Dataset\n",
    "config[\"lang_src\"] = \"noise_vi\"\n",
    "config[\"lang_tgt\"] = \"vi\"\n",
    "config[\"ratio\"] = 0.3\n",
    "config[\"sound_char_ratio\"] = 0.3\n",
    "config[\"no_accent_char_ratio\"] = 0.2 \n",
    "config[\"remove_word_ratio\"] = 0.1\n",
    "config[\"multi_word_ratio\"] = 0.1\n",
    "config[\"face_char_ratio\"] = 0.3\n",
    "config[\"num_noise\"] = 3\n",
    "config[\"train_dataset_path\"] = \"./dataset/9_dataset/train.csv\"\n",
    "\n",
    "# Device\n",
    "config[\"device\"] = \"cuda\"\n",
    "\n",
    "# Model\n",
    "config[\"d_model\"] = 512\n",
    "config[\"num_encoder\"] = 6\n",
    "config[\"num_decoder\"] = 6\n",
    "config[\"nhead\"] = 8\n",
    "config[\"d_ff\"] = 2048\n",
    "config[\"dropout\"] = 0.1\n",
    "config[\"max_len\"] = 100\n",
    "\n",
    "# Word tokenizer\n",
    "config[\"underthesea\"] = True\n",
    "config[\"pyvi\"] = False\n",
    "\n",
    "# Optimier: Adam\n",
    "config[\"weight_decay\"] = 0\n",
    "config[\"lr\"] = 1e-4\n",
    "config[\"lr_scheduler\"] = False\n",
    "config[\"eps\"] = 1e-9\n",
    "config[\"betas\"] = (0.9, 0.98)\n",
    "\n",
    "# Scheduler (config[\"lr_scheduler\"] = True)\n",
    "## LambdaLR\n",
    "config[\"lambdalr\"] = False\n",
    "config[\"warmup_steps\"] = 4000\n",
    "## StepLR\n",
    "config[\"steplr\"] = False\n",
    "config[\"step_size_steplr\"] = 1\n",
    "config[\"gamma_steplr\"] = 0.5\n",
    "\n",
    "# Loss function: Cross_entropy\n",
    "config[\"label_smoothing\"] = 0.1\n",
    "\n",
    "# Train\n",
    "config[\"batch_size_train\"] = 32\n",
    "config[\"batch_size_validation\"] = 32\n",
    "config[\"num_epochs\"] = 5\n",
    "config[\"train_size\"] = 0.9\n",
    "config[\"num_bleu_validation\"] = 100\n",
    "\n",
    "# Validation Bleu metric\n",
    "config[\"max_beam\"] = 1\n",
    "\n",
    "# Test\n",
    "config[\"beam_test\"] = 2\n",
    "config[\"data_test\"] = \"vietnamese_spelling_correction/dataset/dataset.csv\"\n",
    "config[\"f_beta\"] = 0.5\n",
    "\n",
    "# Save\n",
    "config[\"tokenizer_file\"] = \"./dataset/9_dataset/tokenizer_{}.json\"\n",
    "config[\"experiment_name\"] = \"results_train\"\n",
    "config[\"save_config\"] = \"config/config_{0}.json\"\n",
    "config[\"model_folder\"] = \"weights\"\n",
    "config[\"model_basename\"] = \"tmodel_\"\n",
    "config[\"data_path\"] = \"data\"\n",
    "config[\"save_config_pattern\"] = \"config/config_*\"\n",
    "\n",
    "# Different\n",
    "config[\"preload\"] = \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 133318\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1269\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1269\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = load_dataset(\"mt_eng_vietnamese\", \"iwslt2015-en-vi\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': 'Rachel Pike : The science behind a cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'In 4 minutes , atmospheric chemist Rac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'I &amp;apos;d like to talk to you today ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'Headlines that look like this when the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'They are both two branches of the same...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         translation\n",
       "0  {'en': 'Rachel Pike : The science behind a cli...\n",
       "1  {'en': 'In 4 minutes , atmospheric chemist Rac...\n",
       "2  {'en': 'I &apos;d like to talk to you today ab...\n",
       "3  {'en': 'Headlines that look like this when the...\n",
       "4  {'en': 'They are both two branches of the same..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the dataset to a pandas dataframe\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_vi</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rachel Pike : The science behind a climate hea...</td>\n",
       "      <td>Khoa học đằng sau một tiêu đề về khí hậu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In 4 minutes , atmospheric chemist Rachel Pike...</td>\n",
       "      <td>Trong 4 phút , chuyên gia hoá học khí quyển Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I &amp;apos;d like to talk to you today about the ...</td>\n",
       "      <td>Tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Headlines that look like this when they have t...</td>\n",
       "      <td>Có những dòng trông như thế này khi bàn về biế...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They are both two branches of the same field o...</td>\n",
       "      <td>Cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            noise_vi  \\\n",
       "0  Rachel Pike : The science behind a climate hea...   \n",
       "1  In 4 minutes , atmospheric chemist Rachel Pike...   \n",
       "2  I &apos;d like to talk to you today about the ...   \n",
       "3  Headlines that look like this when they have t...   \n",
       "4  They are both two branches of the same field o...   \n",
       "\n",
       "                                                  vi  \n",
       "0           Khoa học đằng sau một tiêu đề về khí hậu  \n",
       "1  Trong 4 phút , chuyên gia hoá học khí quyển Ra...  \n",
       "2  Tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n",
       "3  Có những dòng trông như thế này khi bàn về biế...  \n",
       "4  Cả hai đều là một nhánh của cùng một lĩnh vực ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert [\"translation\"] = {\"en\": \"source\", \"vi\": \"target\"} => {en: \"source\", vi: \"target\"}\n",
    "df[config[\"lang_src\"]] = df[\"translation\"].apply(lambda x: x[\"en\"])\n",
    "df[config[\"lang_tgt\"]] = df[\"translation\"].apply(lambda x: x[\"vi\"])\n",
    "df = df.drop(columns=[\"translation\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x5 the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133318 entries, 0 to 133317\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   noise_vi  133318 non-null  object\n",
      " 1   vi        133318 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_keep = df\n",
    "df = pd.concat([df]*2)\n",
    "df = df.reset_index(drop=True)\n",
    "df_keep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create noise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create noise\n",
    "# Lỗi tương đồng về hình dạng của chữ\n",
    "chars_regrex = '[aàảãáạăằẳẵắặâầẩẫấậoòỏõóọôồổỗốộơờởỡớợeèẻẽéẹêềểễếệuùủũúụưừửữứựiìỉĩíịyỳỷỹýỵnvm]'\n",
    "same_chars = {\n",
    "    'a': ['á', 'à', 'ả', 'ã', 'ạ', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ'],\n",
    "    'o': ['ó', 'ò', 'ỏ', 'õ', 'ọ', 'ô', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ơ','ớ', 'ờ', 'ở', 'ỡ', 'ợ', 'q'],\n",
    "    'e': ['é', 'è', 'ẻ', 'ẽ', 'ẹ', 'ế', 'ề', 'ể', 'ễ', 'ệ', 'ê'],\n",
    "    'u': ['ú', 'ù', 'ủ', 'ũ', 'ụ', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'ư'],\n",
    "    'i': ['í', 'ì', 'ỉ', 'ĩ', 'ị'],\n",
    "    'y': ['ý', 'ỳ', 'ỷ', 'ỹ', 'ỵ', 'v'],\n",
    "    'n': ['m'],\n",
    "    'v': ['y'],\n",
    "    'm': ['n'],\n",
    "}\n",
    "\n",
    "def _char_regrex(text):\n",
    "    match_chars = re.findall(chars_regrex, text)\n",
    "    return match_chars\n",
    "\n",
    "def _random_replace(text, match_chars):\n",
    "    replace_char = match_chars[np.random.randint(low=0, high=len(match_chars), size=1)[0]]\n",
    "    insert_chars = same_chars[unidecode.unidecode(replace_char)]\n",
    "    insert_char = insert_chars[np.random.randint(low=0, high=len(insert_chars), size=1)[0]]\n",
    "    text = text.replace(replace_char, insert_char, 1)\n",
    "\n",
    "    return text\n",
    "\n",
    "def replace_face_char(text):\n",
    "    match_chars = _char_regrex(text)\n",
    "    if len(match_chars) == 0:\n",
    "        return text\n",
    "    text = _random_replace(text, match_chars)\n",
    "    return text\n",
    "# End: lỗi tương đồng về hình dạng của chữ\n",
    "\n",
    "# Lỗi tương đồng về âm thanh khi đọc\n",
    "three_char = {\n",
    "    \"ngh\": [\"ng\"]\n",
    "}\n",
    "two_char = {\n",
    "    \"ng\": [\"g\", \"n\"],\n",
    "    \"gi\": [\"d\", \"v\"],\n",
    "    \"gh\": [\"g\"],\n",
    "    \"ch\": [\"tr\", \"c\"],\n",
    "    \"tr\": [\"ch\"],\n",
    "    \"ph\": [\"p\"],\n",
    "    \"qu\": [\"q\"],\n",
    "    \"kh\": [\"k\"],\n",
    "    \"iê\": [\"i\"],\n",
    "    \"iế\": [\"í\"],\n",
    "    \"iệ\": [\"ị\"],\n",
    "    \"iề\": [\"ì\"],\n",
    "    \"iể\": [\"ỉ\"],\n",
    "    \"iễ\": [\"ĩ\"],\n",
    "}\n",
    "one_char = {\n",
    "    \"g\": [\"gh\", \"r\"],\n",
    "    \"r\": [\"gh\", \"g\"],\n",
    "    \"d\": [\"gi\", \"v\"],\n",
    "    \"k\": [\"kh\"],\n",
    "    \"ph\": [\"p\"],\n",
    "    \"p\": [\"ph\"],\n",
    "    \"q\": [\"qu\"],\n",
    "    \"s\": [\"x\"],\n",
    "    \"x\": [\"s\"],\n",
    "    \"l\": [\"n\"],\n",
    "    \"n\": [\"l\"],\n",
    "    \"v\": [\"gi\", \"d\"],\n",
    "    \"y\": [\"i\"],\n",
    "    \"ý\": [\"í\"],\n",
    "    \"ỳ\": [\"ì\"],\n",
    "    \"ỷ\": [\"ỉ\"],\n",
    "    \"ỹ\": [\"ĩ\"],\n",
    "    \"ỵ\": [\"ị\"],\n",
    "    \"i\": [\"y\"],\n",
    "    \"í\": [\"ý\"],\n",
    "    \"ì\": [\"ỳ\"],\n",
    "    \"ỉ\": [\"ỷ\"],\n",
    "    \"ĩ\": [\"ỹ\"],\n",
    "    \"ị\": [\"ỵ\"],\n",
    "}\n",
    "\n",
    "def replace_sound_char(word):\n",
    "    n_chars = [three_char, two_char, one_char]\n",
    "    for n_char in n_chars:\n",
    "        for char in n_char:\n",
    "            if char in word:\n",
    "                return word.replace(char, random.choice(n_char[char]))\n",
    "    return word\n",
    "# End: lỗi tương đồng về mặt âm thanh khi đọc\n",
    "\n",
    "# Lỗi gõ không dấu\n",
    "def replace_no_accent_char(word):\n",
    "    return unidecode.unidecode(word)\n",
    "# End: lỗi gõ không dấu\n",
    "\n",
    "# Lỗi gõ lặp lại chữ\n",
    "def multi_word(word):\n",
    "    return f\"{word} {word}\"\n",
    "# End: lỗi gõ lặp lại chữ\n",
    "\n",
    "# Lỗi mất chữ\n",
    "def remove_word(word):\n",
    "    return \"\"\n",
    "# End: lỗi mất chữ\n",
    "\n",
    "# create noise function\n",
    "def random_ratio(array: list[int]=[], ratios: float=0.9, size: int=0):\n",
    "    # print(f\"{ratios = }\")\n",
    "    if len(array) != len(ratios):\n",
    "        raise ValueError(\"The length of array and ratios must be the same\")\n",
    "    result_array = [-1] * len(array)\n",
    "    for i in range(len(array)):\n",
    "        num_element = int(size * ratios[i])\n",
    "        sub_array = [array[i]] * num_element\n",
    "        result_array += sub_array\n",
    "    # print(f\"{result_array = }\")\n",
    "    for i in range(len(result_array)):\n",
    "        if result_array[i] == -1:\n",
    "            result_array[i] = array[-1]\n",
    "    np.random.shuffle(result_array)\n",
    "    return result_array\n",
    "\n",
    "def create_noise_random_choice(vi_sent):\n",
    "    words = vi_sent.split()\n",
    "    funcs_noise = [replace_face_char, replace_sound_char, replace_no_accent_char, remove_word, multi_word]\n",
    "    # funcs_noise = [replace_face_char, replace_sound_char, replace_no_accent_char, multi_word]\n",
    "    if len(words) <= 1:\n",
    "        return vi_sent\n",
    "    func_noise = funcs_noise[random.randint(0, len(funcs_noise) - 1)]\n",
    "    idx = random.randint(0, len(words) - 1)\n",
    "    words[idx] = func_noise(words[idx])\n",
    "    res = \"\"\n",
    "    for i in range(len(words)):\n",
    "        if words[i] == \"\":\n",
    "            continue\n",
    "        res = res + \" \" + words[i]\n",
    "    return res.strip()\n",
    "\n",
    "def create_noise(config, vi_sent):\n",
    "    ratio = config[\"ratio\"]\n",
    "    face_char_ratio = round(config[\"face_char_ratio\"] * ratio, 3)\n",
    "    sound_char_ratio = round(config[\"sound_char_ratio\"] * ratio, 3)\n",
    "    no_accent_char_ratio = round(config[\"no_accent_char_ratio\"] * ratio, 3)\n",
    "    remove_word_ratio = round(config[\"remove_word_ratio\"] * ratio, 3)\n",
    "    multi_word_ratio = round(config[\"multi_word_ratio\"] * ratio, 3)\n",
    "    words = vi_sent.split()\n",
    "    funcs_noise = [replace_face_char, replace_sound_char, replace_no_accent_char, remove_word, multi_word]\n",
    "    # funcs_noise = [replace_face_char, replace_sound_char, replace_no_accent_char, multi_word]\n",
    "    ratios = [face_char_ratio,\n",
    "              sound_char_ratio,\n",
    "              no_accent_char_ratio,\n",
    "              remove_word_ratio,\n",
    "              multi_word_ratio,\n",
    "              1 - (face_char_ratio + sound_char_ratio + no_accent_char_ratio + remove_word_ratio + multi_word_ratio)]\n",
    "            #   1 - (face_char_ratio + sound_char_ratio + no_accent_char_ratio + multi_word_ratio)]\n",
    "    rand_error = random_ratio(\n",
    "        array=list(range(len(ratios))),\n",
    "        ratios=ratios,\n",
    "        size = len(words)\n",
    "    )\n",
    "    # print(f\"{ rand_error = }\")\n",
    "    res = \"\"\n",
    "    for i in range(len(words)):\n",
    "        if rand_error[i] == len(ratios) - 1:\n",
    "            res = res + \" \" + words[i]\n",
    "        else:\n",
    "            # print(f\"{rand_error[i] = }\")\n",
    "            change_word = (funcs_noise[rand_error[i]])(words[i])\n",
    "            if change_word != \"\":\n",
    "                res = res + \" \" + change_word\n",
    "    return res.strip()\n",
    "# end create noise\n",
    "\n",
    "def clean_data(text, lang):\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = (text.lower()).replace(\" '\", \"'\")\n",
    "    if lang == \"en\":\n",
    "        text = contractions.fix(text)\n",
    "    return handle_special_char(text)\n",
    "\n",
    "def handle_special_char(sent):\n",
    "    sent = re.sub(r'([.,!?;(){}\\[\\]])', r' \\1 ', sent)\n",
    "    sent = re.sub(r'\\s{2,}', ' ', sent)\n",
    "    sent = sent.strip()\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add noise in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_vi</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Khoa học đằng sau một tiêu đề về khí hậu</td>\n",
       "      <td>Khoa học đằng sau một tiêu đề về khí hậu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trong 4 phút , chuyên gia hoá học khí quyển Ra...</td>\n",
       "      <td>Trong 4 phút , chuyên gia hoá học khí quyển Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "      <td>Tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Có những dòng trông như thế này khi bàn về biế...</td>\n",
       "      <td>Có những dòng trông như thế này khi bàn về biế...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "      <td>Cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            noise_vi  \\\n",
       "0           Khoa học đằng sau một tiêu đề về khí hậu   \n",
       "1  Trong 4 phút , chuyên gia hoá học khí quyển Ra...   \n",
       "2  Tôi muốn cho các bạn biết về sự to lớn của nhữ...   \n",
       "3  Có những dòng trông như thế này khi bàn về biế...   \n",
       "4  Cả hai đều là một nhánh của cùng một lĩnh vực ...   \n",
       "\n",
       "                                                  vi  \n",
       "0           Khoa học đằng sau một tiêu đề về khí hậu  \n",
       "1  Trong 4 phút , chuyên gia hoá học khí quyển Ra...  \n",
       "2  Tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n",
       "3  Có những dòng trông như thế này khi bàn về biế...  \n",
       "4  Cả hai đều là một nhánh của cùng một lĩnh vực ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign source by target\n",
    "df[config[\"lang_src\"]] = df[config[\"lang_tgt\"]]\n",
    "df_keep[config[\"lang_src\"]] = df_keep[config[\"lang_tgt\"]]\n",
    "df_keep.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7883/2741826605.py:176: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_vi</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>khoa học đằng sau một tiêu đề về khí hậu</td>\n",
       "      <td>khoa học đằng sau một tiêu đề về khí hậu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trong 4 phút phút , chuyên gia gia hoá học khí...</td>\n",
       "      <td>trong 4 phút , chuyên gia hoá học khí quyển ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tôy muốn cho các bạn biết giề sụ to lớn của nh...</td>\n",
       "      <td>tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>có nhung dòng trông như thế này khi bàn vể biế...</td>\n",
       "      <td>có những dòng trông như thế này khi bàn về biế...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cả hai đều là một nhánh của cùg một lĩnh vực t...</td>\n",
       "      <td>cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            noise_vi  \\\n",
       "0           khoa học đằng sau một tiêu đề về khí hậu   \n",
       "1  trong 4 phút phút , chuyên gia gia hoá học khí...   \n",
       "2  tôy muốn cho các bạn biết giề sụ to lớn của nh...   \n",
       "3  có nhung dòng trông như thế này khi bàn vể biế...   \n",
       "4  cả hai đều là một nhánh của cùg một lĩnh vực t...   \n",
       "\n",
       "                                                  vi  \n",
       "0           khoa học đằng sau một tiêu đề về khí hậu  \n",
       "1  trong 4 phút , chuyên gia hoá học khí quyển ra...  \n",
       "2  tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n",
       "3  có những dòng trông như thế này khi bàn về biế...  \n",
       "4  cả hai đều là một nhánh của cùng một lĩnh vực ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create noise for source\n",
    "df[config[\"lang_tgt\"]] = df[config[\"lang_tgt\"]].apply(lambda x: clean_data(x, config[\"lang_tgt\"]))\n",
    "df[config[\"lang_src\"]] = df[config[\"lang_src\"]].apply(lambda x: create_noise(config, clean_data(x, config[\"lang_src\"])))\n",
    "df_keep[config[\"lang_tgt\"]] = df_keep[config[\"lang_tgt\"]].apply(lambda x: clean_data(x, config[\"lang_tgt\"]))\n",
    "df_keep[config[\"lang_src\"]] = df_keep[config[\"lang_src\"]].apply(lambda x: clean_data(x, config[\"lang_src\"]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399954 entries, 0 to 399953\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   noise_vi  399954 non-null  object\n",
      " 1   vi        399954 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# merge df and df_keep\n",
    "df = pd.concat([df, df_keep])\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 370680 entries, 0 to 370679\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   noise_vi  370680 non-null  object\n",
      " 1   vi        370680 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# filter especial char not in vietnamese\n",
    "def filter_especial_char(sent):\n",
    "    especial_char = \"wzjzf\"\n",
    "    for char in sent:\n",
    "        if char in especial_char:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# filter df with src and tgt\n",
    "df = df[df[config[\"lang_src\"]].apply(lambda x: filter_especial_char(x))]\n",
    "df = df[df[config[\"lang_tgt\"]].apply(lambda x: filter_especial_char(x))]\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentences(dataset, lang):\n",
    "    for item in dataset:\n",
    "        yield item\n",
    "\n",
    "def get_or_build_tokenizer(config, dataset, lang):\n",
    "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
    "    if not Path.exists(tokenizer_path):\n",
    "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "        trainer = WordLevelTrainer(vocab_size=50000, special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
    "        tokenizer.train_from_iterator(get_all_sentences(dataset, lang), trainer=trainer)\n",
    "        tokenizer.save(str(tokenizer_path))\n",
    "    else:\n",
    "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
    "    return tokenizer\n",
    "\n",
    "def get_tokenizer(config, dataset):\n",
    "    tokenizer_src = get_or_build_tokenizer(config, dataset[config[\"lang_src\"]], config[\"lang_src\"])\n",
    "    tokenizer_tgt = get_or_build_tokenizer(config, dataset[config[\"lang_tgt\"]], config[\"lang_tgt\"])\n",
    "    return tokenizer_src, tokenizer_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_src, tokenizer_tgt = get_tokenizer(config, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27601, 14872)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter len tokenzier on df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303371 entries, 0 to 303370\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   noise_vi  303371 non-null  object\n",
      " 1   vi        303371 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_vi</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trong 4 phút phút , chuyên gia gia hoá học khí...</td>\n",
       "      <td>trong 4 phút , chuyên gia hoá học khí quyển ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tôy muốn cho các bạn biết giề sụ to lớn của nh...</td>\n",
       "      <td>tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>có nhung dòng trông như thế này khi bàn vể biế...</td>\n",
       "      <td>có những dòng trông như thế này khi bàn về biế...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cả hai đều là một nhánh của cùg một lĩnh vực t...</td>\n",
       "      <td>cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>các tiêu tiêu đề đâi trông như thế nàỷ khi ban...</td>\n",
       "      <td>các tiêu đề gần đây trông như thế này khi ban ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303366</th>\n",
       "      <td>mối liên kết chung trong những việc chúng tôi ...</td>\n",
       "      <td>mối liên kết chung trong những việc chúng tôi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303367</th>\n",
       "      <td>nelson maldela từng nói giữa những năm 2000 , ...</td>\n",
       "      <td>nelson maldela từng nói giữa những năm 2000 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303368</th>\n",
       "      <td>nó là do con người và có thể ngăn chặn và diệt...</td>\n",
       "      <td>nó là do con người và có thể ngăn chặn và diệt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303369</th>\n",
       "      <td>tôi muốn kết luận rằng hành động của hàng ngàn...</td>\n",
       "      <td>tôi muốn kết luận rằng hành động của hàng ngàn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303370</th>\n",
       "      <td>paul pholeros : làm sao để bớt nghèo khổ ? hãy...</td>\n",
       "      <td>paul pholeros : làm sao để bớt nghèo khổ ? hãy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303371 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 noise_vi  \\\n",
       "0       trong 4 phút phút , chuyên gia gia hoá học khí...   \n",
       "1       tôy muốn cho các bạn biết giề sụ to lớn của nh...   \n",
       "2       có nhung dòng trông như thế này khi bàn vể biế...   \n",
       "3       cả hai đều là một nhánh của cùg một lĩnh vực t...   \n",
       "4       các tiêu tiêu đề đâi trông như thế nàỷ khi ban...   \n",
       "...                                                   ...   \n",
       "303366  mối liên kết chung trong những việc chúng tôi ...   \n",
       "303367  nelson maldela từng nói giữa những năm 2000 , ...   \n",
       "303368  nó là do con người và có thể ngăn chặn và diệt...   \n",
       "303369  tôi muốn kết luận rằng hành động của hàng ngàn...   \n",
       "303370  paul pholeros : làm sao để bớt nghèo khổ ? hãy...   \n",
       "\n",
       "                                                       vi  \n",
       "0       trong 4 phút , chuyên gia hoá học khí quyển ra...  \n",
       "1       tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n",
       "2       có những dòng trông như thế này khi bàn về biế...  \n",
       "3       cả hai đều là một nhánh của cùng một lĩnh vực ...  \n",
       "4       các tiêu đề gần đây trông như thế này khi ban ...  \n",
       "...                                                   ...  \n",
       "303366  mối liên kết chung trong những việc chúng tôi ...  \n",
       "303367  nelson maldela từng nói giữa những năm 2000 , ...  \n",
       "303368  nó là do con người và có thể ngăn chặn và diệt...  \n",
       "303369  tôi muốn kết luận rằng hành động của hàng ngàn...  \n",
       "303370  paul pholeros : làm sao để bớt nghèo khổ ? hãy...  \n",
       "\n",
       "[303371 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_condition(pair, config):\n",
    "    sent_src = pair[config[\"lang_src\"]]\n",
    "    sent_tgt = pair[config[\"lang_tgt\"]]\n",
    "    if type(sent_src) != str or type(sent_tgt) != str:\n",
    "        return False\n",
    "    \n",
    "    token_ids_src = tokenizer_src.encode(sent_src).ids\n",
    "    token_ids_tgt = tokenizer_tgt.encode(sent_tgt).ids\n",
    "\n",
    "    min_len = min(len(token_ids_src), len(token_ids_tgt))\n",
    "    max_len = max(len(token_ids_src), len(token_ids_tgt))\n",
    "    if min_len > 10 and max_len <= config[\"max_len\"] - 4:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df = df[df.apply(lambda x: create_condition(x, config), axis=1)].reset_index(drop=True)\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete tokenizer file\n",
    "def delete_tokenizer_file(config):\n",
    "    tokenizer_file = Path(config[\"tokenizer_file\"].format(config[\"lang_src\"]))\n",
    "    if Path.exists(tokenizer_file):\n",
    "        Path.unlink(tokenizer_file)\n",
    "    tokenizer_file = Path(config[\"tokenizer_file\"].format(config[\"lang_tgt\"]))\n",
    "    if Path.exists(tokenizer_file):\n",
    "        Path.unlink(tokenizer_file)\n",
    "\n",
    "delete_tokenizer_file(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_src, tokenizer_tgt = get_tokenizer(config, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26666, 14128)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_vi</th>\n",
       "      <th>vi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trong 4 phút phút , chuyên gia gia hoá học khí...</td>\n",
       "      <td>trong 4 phút , chuyên gia hoá học khí quyển ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tôy muốn cho các bạn biết giề sụ to lớn của nh...</td>\n",
       "      <td>tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>có nhung dòng trông như thế này khi bàn vể biế...</td>\n",
       "      <td>có những dòng trông như thế này khi bàn về biế...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cả hai đều là một nhánh của cùg một lĩnh vực t...</td>\n",
       "      <td>cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>các tiêu tiêu đề đâi trông như thế nàỷ khi ban...</td>\n",
       "      <td>các tiêu đề gần đây trông như thế này khi ban ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303366</th>\n",
       "      <td>mối liên kết chung trong những việc chúng tôi ...</td>\n",
       "      <td>mối liên kết chung trong những việc chúng tôi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303367</th>\n",
       "      <td>nelson maldela từng nói giữa những năm 2000 , ...</td>\n",
       "      <td>nelson maldela từng nói giữa những năm 2000 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303368</th>\n",
       "      <td>nó là do con người và có thể ngăn chặn và diệt...</td>\n",
       "      <td>nó là do con người và có thể ngăn chặn và diệt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303369</th>\n",
       "      <td>tôi muốn kết luận rằng hành động của hàng ngàn...</td>\n",
       "      <td>tôi muốn kết luận rằng hành động của hàng ngàn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303370</th>\n",
       "      <td>paul pholeros : làm sao để bớt nghèo khổ ? hãy...</td>\n",
       "      <td>paul pholeros : làm sao để bớt nghèo khổ ? hãy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303371 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 noise_vi  \\\n",
       "0       trong 4 phút phút , chuyên gia gia hoá học khí...   \n",
       "1       tôy muốn cho các bạn biết giề sụ to lớn của nh...   \n",
       "2       có nhung dòng trông như thế này khi bàn vể biế...   \n",
       "3       cả hai đều là một nhánh của cùg một lĩnh vực t...   \n",
       "4       các tiêu tiêu đề đâi trông như thế nàỷ khi ban...   \n",
       "...                                                   ...   \n",
       "303366  mối liên kết chung trong những việc chúng tôi ...   \n",
       "303367  nelson maldela từng nói giữa những năm 2000 , ...   \n",
       "303368  nó là do con người và có thể ngăn chặn và diệt...   \n",
       "303369  tôi muốn kết luận rằng hành động của hàng ngàn...   \n",
       "303370  paul pholeros : làm sao để bớt nghèo khổ ? hãy...   \n",
       "\n",
       "                                                       vi  \n",
       "0       trong 4 phút , chuyên gia hoá học khí quyển ra...  \n",
       "1       tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n",
       "2       có những dòng trông như thế này khi bàn về biế...  \n",
       "3       cả hai đều là một nhánh của cùng một lĩnh vực ...  \n",
       "4       các tiêu đề gần đây trông như thế này khi ban ...  \n",
       "...                                                   ...  \n",
       "303366  mối liên kết chung trong những việc chúng tôi ...  \n",
       "303367  nelson maldela từng nói giữa những năm 2000 , ...  \n",
       "303368  nó là do con người và có thể ngăn chặn và diệt...  \n",
       "303369  tôi muốn kết luận rằng hành động của hàng ngàn...  \n",
       "303370  paul pholeros : làm sao để bớt nghèo khổ ? hãy...  \n",
       "\n",
       "[303371 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303371 entries, 0 to 303370\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   noise_vi  303371 non-null  object\n",
      " 1   vi        303371 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# shuffle df\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.info()\n",
    "# save dataset\n",
    "df.to_csv(config[\"train_dataset_path\"], index=False)\n",
    "# load dataset\n",
    "df = pd.read_csv(config[\"train_dataset_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get max len token id of noise_vi and vi\n",
    "def get_max_len_token_id(dataset, lang):\n",
    "    max_len = 0\n",
    "    for item in dataset:\n",
    "        if (type(item) != str):\n",
    "            continue\n",
    "        if lang == config[\"lang_src\"]:\n",
    "            token_len = len(tokenizer_src.encode(item).ids)\n",
    "            max_len = max(max_len, token_len)\n",
    "        else:\n",
    "            token_len = len(tokenizer_tgt.encode(item).ids)\n",
    "            max_len = max(max_len, token_len)\n",
    "    return max_len\n",
    "\n",
    "max_len_src = get_max_len_token_id(df[config[\"lang_src\"]], config[\"lang_src\"])\n",
    "max_len_tgt = get_max_len_token_id(df[config[\"lang_tgt\"]], config[\"lang_tgt\"])\n",
    "\n",
    "max_len_src, max_len_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184197, 119174, 303371, 303371)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number source != target\n",
    "cnt_diff, cnt_same = 0, 0\n",
    "for id in range(len(df)):\n",
    "    src = df.iloc[id][config[\"lang_src\"]]\n",
    "    tgt = df.iloc[id][config[\"lang_tgt\"]]\n",
    "    cnt_diff += src != tgt\n",
    "    cnt_same += src == tgt\n",
    "\n",
    "cnt_diff, cnt_same, cnt_diff + cnt_same, len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read custom_dataset.csv\n",
    "df = pd.read_csv(config[\"train_dataset_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 90% train, 10% validation\n",
    "train_size = int(len(df) * config[\"train_size\"])\n",
    "# shuffle the dataset\n",
    "train_df = df[:train_size]\n",
    "validation_df = df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 273033 entries, 0 to 273032\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   noise_vi  273033 non-null  object\n",
      " 1   vi        273033 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30338 entries, 273033 to 303370\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   noise_vi  30338 non-null  object\n",
      " 1   vi        30338 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 474.2+ KB\n"
     ]
    }
   ],
   "source": [
    "validation_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 273033 to 273132\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   noise_vi  100 non-null    object\n",
      " 1   vi        100 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   noise_vi  100 non-null    object\n",
      " 1   vi        100 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# create test bleu dataset 100 samples from validation dataset\n",
    "test_validation_df = validation_df[:config[\"num_bleu_validation\"]]\n",
    "test_validation_df.info()\n",
    "# create test bleu train dataset 100 samples from train dataset\n",
    "test_train_df = train_df[:config[\"num_bleu_validation\"]]\n",
    "test_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, ds, src_lang, tgt_lang):\n",
    "        super().__init__()\n",
    "        self.ds = ds\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_target_pair = self.ds.iloc[idx]\n",
    "        src_text = src_target_pair[self.src_lang]\n",
    "        tgt_text = src_target_pair[self.tgt_lang]\n",
    "\n",
    "        return (src_text, tgt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_df = CustomDataset(train_df, config[\"lang_src\"], config[\"lang_tgt\"])\n",
    "custom_validation_df = CustomDataset(validation_df, config[\"lang_src\"], config[\"lang_tgt\"])\n",
    "custom_bleu_validation_df = CustomDataset(test_validation_df, config[\"lang_src\"], config[\"lang_tgt\"])\n",
    "custom_bleu_train_df = CustomDataset(test_train_df, config[\"lang_src\"], config[\"lang_tgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_train_df.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_validation_df.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bleu_validation_df.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bleu_train_df.__getitem__(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
